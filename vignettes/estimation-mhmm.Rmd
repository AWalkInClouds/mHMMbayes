---
title: "Estimation of the multilevel hidden Markov model"
author: "Emmeke Aarts"
date: "`r Sys.Date()`"
bibliography: bibliography.bib
link-citations: yes
output: 
  pdf_document:
  citation_package: biblatex    
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

There are several methods to estimate the parameters of an HMM. To be complete, we discuss two other methods typically used before proceeding to explaining the used Bayesian estimation mehtod. Note that all these methods assume that the number of states is known from the context of the application, i.e., specified by the user. The issue of determining the number of states is discussed in the Tutorial vignette.\
After discussing the simplified case of estimating the parameters where the data consists of only one observed sequence, we proceed with elaborating on estimating the paramters of a multilevel hidden Markov model. 

\section{Estimating the parameters of the HMM} 
\subsubsection{Maximum likelihood (ML)}
ML estimation can be used to estimate the parameters of the HMM. The relevant likelihood function has a convenient form: 
\begin{equation}
L_T = \mathbf{\delta P}(o_1) \mathbf{\Gamma P}(o_2)\mathbf{\Gamma P}(o_3) \ldots \mathbf{\Gamma P}(o_T) \mathbf{1'}. 
\label{HMMlik}
\end{equation}
In equation \ref{HMMlik}, $\mathbf{P}(o_t)$ denotes a diagonal matrix with the state-dependent conditional probabilities of observing $O_t = o$ as entries, $\mathbf{\delta}$ denotes the distribution of the initial probabilities $\pi_i$,  $\mathbf{\Gamma}$ denotes the transition probability matrix, and $\mathbf{1'}$ is a column vector consisting of $m$ (i.e., the number of distinct states) elements which all have the value one. Direct maximization of the log-likelihood poses no problems even for very long sequences, provided measures are taken to avoid numerical underflow\footnote{In case of a discrete state-dependent distribution, multiplication of the elements of the likelihood function, being made up of probabilities, results in progressively smaller outcomes as one proceeds in the function from 1 to $T$, eventually rounding to zero. To avoid this phenomenon, referred to as numerical underflow, a so-called scaling factor is implemented, see e.g., Zucchini and MacDonald (2009)}. 

\subsubsection{Expectation Maximization (EM) or Baum-Welch algorithm}
The EM algorithm [@dempster1977], in this context also known as the Baum-Welch algorithm [@baum1970; @Rabiner1989], can also be used to maximize the log-likelihood function. Here, the unobserved latent states are treated as missing data, and quantities known as the forward and the backward probabilities are used to obtain the 'complete-data log-likelihood' of the HMM parameters: the log-likelihood based on both the observed event sequence and the unobserved, or "missing", latent states. The forward probabilities $\boldsymbol{\alpha}_t (i)$ denote the joint probability of the observed event sequence from time point 1 to $t$ and state $S$ at time point $t$ being $i$:
\begin{equation}
\label{forward}
\boldsymbol{\alpha}_t (i) = Pr(O_1 = o_1, O_2 = o_2, \ldots, O_t = o_t, S_t = i).
\end{equation}
The name "forward probabilities" derives from the fact that when computing the forward probabilities $\boldsymbol{\alpha}_t$, one evaluates the sequence of hidden states in the chronological order (i.e., forward in time) until time point $t$. The backward probabilities $\boldsymbol{\beta}_t (i)$ denote the conditional probability of the observed event sequence after time point $t$ until the end, so from $t+1, t+2, \ldots ,T$, given that state $S$ at time point $t$ equals $i$:  
\begin{equation}
\boldsymbol{\beta}_t (i) = Pr(O_{t+1} = o_{t+1}, O_{t+2} = o_{t+2}, \ldots, O_T = o_T \mid S_t = i).
\end{equation}
When computing the backward probabilities $\boldsymbol{\beta}_t$, one evaluates the sequence of hidden states in the reversed order, i.e., from $S_T, S_{T-1}, \ldots, S_{t+1}$. The forward and backward probabilities together cover the complete event sequence from $t = 1$ to $T$, and combined give the joint probability of the complete event sequence and state $S$ at time point $t$ being $i$:
\begin{equation}
\boldsymbol{\alpha}_t (i)\boldsymbol{\beta}_t (i) = Pr(O_{1} = o_{1}, O_{2} = o_{2}, \ldots, O_T = o_T, S_t = i).
\label{eqFW}
\end{equation} 
We refer to @cappe2005 for a discussion on the advantages of combining forward and backward probability information in the EM algorithm over direct maximization of the likelihood for the HMM. 

\subsubsection{Bayesian estimation}
A third approach is to use Bayesian estimation to infer the parameters of the HMM. We refer to e.g., @gelman2014, @lynch2007, @rossi2012 for an in-depth exposition of Bayesian statistics. In general terms, the difference between frequentist and Bayesian estimation is the following. In frequentist estimation, we view the parameters as fixed entities in the population, which are subject only to sampling fluctuation (as quantified in the standard error of the estimate). In Bayesian estimation, however, we assume that each parameter follows a given  distribution. The general shape of this distribution is determined beforehand, using a prior distribution. This prior distribuiton not only determines the shape of the parameter distribuiton, but also allows for giving some information with respect to the most likely values of the parameter that is estimated. To arrive at the final distribuiton for the parameter - which is called the posterior distribution -, the prior distribution is combined with the likelihood function of the data using Bayes' theorem. Here, the likelihood function provides us with the probability of the data given the parameters. While any aspect of these distributions may be of interest, the emphasis is usually on the mean (or median) of the posterior distribution, which serves as the point estimate of the parameter of interest (analogous to the frequentist parameter estimates). In the event that one has no or vague expectations about the possible parameter values, one can specify "non-informative" priors (e.g., uniform distribution). That is, one can choose parameters of the prior distributions, so called hyper-parameters, such that the parameters may assume a wide range of possible values. Non-informative priors therefore express a lack of knowledge.\
In the implemented hidden Markov model, both the transitions from state $i$ at time point $t$ to any of the other states at time point $t + 1$ and the observed outcomes within state $i$ follow a categorical distribution, with parameter sets $\mathbf{\Gamma}_i$ (i.e., the probabilities in row $i$ of the transition probability matrix $\mathbf{\Gamma}$) and $\boldsymbol{\theta}_i$ (i.e., the state $i$ dependent probabilities of observing an act). A convenient (conjugate) prior distribution on the parameters of the categorical distribution is a (symmetric) Dirichlet distribution (see the glossary at the end of this chapter for a short description). We assume that the rows of $\mathbf{\Gamma}$ and the state-dependent probabilities $\boldsymbol{\theta}_i$ are independent. That is,
\begin{align}
S_{t = 2, \ldots, T} \: \sim \mathbf{\Gamma}_{S_{t-1}} \quad &\text{with} \quad \mathbf{\Gamma}_i \: \sim \text{Dir}(\mathbf{a}_{10}) \quad \text{and} \label{gammaDirPrior}\\  O_{t = 1, \ldots, T} \: \sim\boldsymbol{\theta}_{S_t} \quad &\text{with} \quad \boldsymbol{\theta}_i 	\: \sim \text{Dir}(\mathbf{a}_{20}), \label{pDirPrior}
\end{align}
where the probability distribution of the current state $S_t$ is given by the row of the transition probability matrix $\mathbf{\Gamma}$ corresponding to the previous state in the hidden state sequence $S_{t-1}$. The probability distribution of $S_t$ given by $\mathbf{\Gamma}$ holds for states after the first time point, i.e., t starts at 2 as there is no previous state in the hidden state sequence for state $S$ at $t = 1$. The probability of the first state in the hidden state sequence $S_1$ is given by the initial probabilities of the states $\pi_i$. The probability distribution of the observed event $O_t$ is given by state-dependent probabilities $\boldsymbol{\theta}_i$ corresponding to the current state $S_t$. The hyper-parameter $\mathbf{a}_{10}$ of the prior Dirichlet distribution on $\mathbf{\Gamma}_i$ is a vector with length equal to the number of states $m$, and the hyper-parameter $\mathbf{a}_{20}$ of the prior Dirichlet distribution on $\boldsymbol{\theta}_i$ is a vector with length equal to the number of categorical outcomes $q$. Note that the hyper-parameter values are assumed invariant over the states $i$. The initial probabilities of the states $\pi_i$ are assumed to coincide with the stationary distribution of $\boldsymbol{\Gamma}$ and are therefore not independent (to-be-estimated) parameters.\
Given these distributions, our goal is to construct the joint posterior distribution of the hidden state sequence and the parameter estimates, given the observed event sequence and the hyper-parameters
\begin{equation}
\Pr\big((S_t), \mathbf{\Gamma}_i ,  \boldsymbol{\theta}_i \mid (O_t)\big)
\propto \Pr\big((O_t) \mid (S_t), \boldsymbol{\theta}_i  \big) \Pr\big((S_t) \mid \mathbf{\Gamma}_i  \big) \Pr\big(\mathbf{\Gamma}_i  \mid \mathbf{a}_{10} \big) \Pr\big(\boldsymbol{\theta}_i \mid \mathbf{a}_{20} \big)
% \mathbf{a}_{10}, \mathbf{a}_{20}
\end{equation}
by drawing samples from the posterior distribution. By applying a Gibbs sampler, we can iteratively sample from the appropriate conditional posterior distributions of $S_t$, $\mathbf{\Gamma}_i$ and $\boldsymbol{\theta}_i$, given the remaing parameters in the model. In short, the Gibbs sampler iterates between the following two steps: first the hidden state sequence $S_1, S_2, \ldots, S_T$ is sampled, given, the observed event sequence $O_1, O_2, \ldots, O_T$, and the current values of the parameters $\mathbf{\Gamma}$ and $\boldsymbol{\theta}_i$. Subsequently, the remaing parameters in the model ($\mathbf{\Gamma}_i$ and $\boldsymbol{\theta}_i$) are updated by sampling them conditional on the sampled hidden state sequence $S_1, S_2, \ldots, S_T$ and observed event sequence $O_1, O_2, \ldots, O_T$. In the section "\textit{Hybrid Metropolis within Gibbs sampler used to fit the multilevel HMM}" , we provide a more detailed description of how the Gibbs sampler proceeds for the HMM.\
As it generally takes a number of iterations before the Gibbs sampler converges to the appropriate region of the posterior distribution, the initial iterations are usually discarded as a 'burn-in' period. The remaining sampled values of $\mathbf{\Gamma}_i$ and $\boldsymbol{\theta}_i$ provide the posterior distributions of their respective parameters. \
Sampling the hidden state sequence  of the HMM by means of the Gibbs sampler can be performed in various ways. Here, we use the approach outlined by @scott2002. That is, we use the forward-backward Gibbs sampler, in which  first the forward probabilities $\boldsymbol{\alpha}_{t}(i)$ (i.e., the joint probability of state $S = i$ at time point $t$ and the observed event sequence from time point 1 to $t$) as given in equation \ref{forward} are obtained, after which the hidden state sequence is sampled in a backward run (i.e., drawing $S_T, S_{T-1}, \ldots, S_1$) using the corresponding forward probabilities $\boldsymbol{\alpha}_{T:1}$. The forward-backward Gibbs sampler produces sampled values that rapidly represent the complete area of the posterior distribution, and produces useful quantities as byproducts, such as the log-likelihood of the observed data given the current draws of the parameters in each iteration [@scott2002].\
A problem that can arise when using Bayesian estimation in this context is "label switching", i.e., as the hidden states of the HMM have no a priori ordering or interpretation, their labels (i.e., which state represents what) can switch over the iterations of the Gibbs sampler, without affecting the likelihood of the model [@scott2002; @jasra2005]. As a result, the marginal posterior distributions of the parameters are impossible to interpret because they represent the distribution of multiple states. Sometimes, using reasonable starting values (i.e., the user-specified parameter values of the "zero-th" iteration used to start the MCMC sampler) suffices to prevent label switching. Otherwise, possible solutions are to set constraints on the parameters of the state-dependent distribution, or use (weakly) informative priors on the state-dependent distributions [@scott2002]. Hence, before making inferences from the obtained marginal distributions, one should first assess if the problem of label switching is present (e.g., by using plots of the sampled parameter values of the state-dependent distributions over the iterations), and if necessary, take steps to prevent the problem of label switching. Note that the use of reasonable starting values sufficed to prevent label switching in all of the data analyses described in this chapter, hence we did not need to take extra steps to prevent this problem. \
Both EM and Bayesian Gibbs sampling are viable inferential procedures for HMMs, but for more complex HMMs such as multilevel HMMs, the Bayesian estimation method has several advantages (e.g., lower computational cost, and less computation time) over the EM algorithm. We refer to @ryden2008 for a comparison on frequentist (i.e., the EM algorithm) and Bayesian approaches. 

\section{Estimating the parameters of the multilevel HMM using Bayesian estimation} 
Bayesian estimation is particularly suited to multilevel models. In the multilevel model, we have a multi-layered structure in the parameters: individual level parameters at the first level pertaining to the observations within an individual, and population level parameters at the second level that describe the variation in the individual level parameters in the population as inferred from the sample. To illustrate the multilevel model, suppose that we have $K$ subjects for which we have each $H$ observations on their number of visits to the feeding station per day $y$, i.e., subject $k \in \{1, 2, \ldots, K\}$ and observation $h \in \{1, 2, \ldots, H\}$. Hence, at the first level, we have daily observations on the number of feeding station visits within subjects: $y_{11}$, $y_{12}$, $\ldots$, $y_{1H}$, $y_{21}$, $y_{22}$, $\ldots$, $y_{2H}$, $y_{K1}$, $y_{K2}$, $\ldots$, $y_{KH}$. Using a multilevel model, the observations of each subject are distributed according to the same distribution $Q$, but each subject has its own parameter set $\theta_k$. That is:
\begin{equation}
y_{kh} \sim Q(\theta_k). 
\end{equation}
In addition, the subject-specific parameter sets  $\theta_k$ are realizations of a common population level distribution $W$ with parameter set $\Lambda$:
\begin{equation}
\theta_k \sim W(\Lambda).
\end{equation}
That is, in the multilevel model, the individual level model parameters that pertain to the observations within a subject are assumed to be random draws from a given distribution, and, as such, are denoted as "random", independent of the used estimation method (i.e., Bayesian or classical frequentist estimation). This multi-layered structure fits naturally into a Bayesian paradigm since in Bayesian estimation, model parameters are by definition viewed as random, i.e., to follow a given distribution, where the prior distribution expresses the prior expectations with respect to the most likely values of the model parameters. In the multilevel model, the prior expectations of the individual level model parameter values are reflected in the population level distribution. Hence, using Bayesian estimation, the population level distribution is given by the prior distribution of the individual level model parameters.  The population level prior distribution provides information on the location (e.g., mean) of the individual level (i.e., subject-specific) parameters, and on the variation in the individual level parameters. As the Normal distribution is a flexible distribution with parameters that easily relate to this interpretation, the population level prior distribution is often taken to be a normal distribution. \
To illustrate the notion of the population level prior distribution, suppose we assume a Poisson distribution for the observations on daily number of feeding station visits within each subject k, and a Normal population level prior distribution on the Poisson mean. In this case, the set of hyper-parameters (i.e., the parameters of the population level prior distribution, here the mean ($\Lambda_\mu$) and variance ($\Lambda_{\sigma^2}$) of the Normal prior distribution) on the Poisson mean denote the population mean number of feeding station visits per day over subjects, and the variation in the mean number of feeding station visits per day between subjects. \
Finally, in fitting the multilevel model using Bayesian estimation, a prior distribution is placed on each of these hyper-parameters. Prior distributions on hyper-parameters are referred to as hyper-priors and allow the hyper-parameters to have a distribution instead of being fixed as in the non- multilevel model. That is, as the parameters that characterize the population level prior distribution (i.e., the hyper-parameters) are now also quantities of interest (i.e., to-be-estimated), they are viewed as random in Bayesian estimation methods. The randomness in the hyper-parameters is thus specific to the Bayesian estimation method of the multilevel model, in contrast to the randomness in the individual level parameters. \\
To continue our example, the hyper-prior on the mean of the Normal prior distribution for the subject level mean of daily number of visits to the feeding station denote our prior belief on the mean number of visits to the feeding station in the population. The hyper-prior on the variance of the Normal prior distribution for the subject level mean of daily number of visits to the feeding station denote our prior belief on how much this mean number of visits to the feeding station varies over subjects.  Often, the hyper-prior distribution and its values are chosen to be vague (i.e., not informative), like a uniform distribution: 
\begin{align}
\Lambda_\mu & \: \sim U(0, 100),\\ \nonumber
\Lambda_{\sigma^2} & \:  \sim U(0, 500).
\end{align}
See e.g., @gelman2014, @lynch2007, @rossi2012 for an in-depth exposition of various multilevel Bayesian models and e.g. @Snijders2011, @Hox2010, @Goldstein2011 for coverage of the classical, frequentist approach to multilevel (also called hierarchical or random effects) models.\
The present multilevel data comprises $O_{kt}$ observations for subject $k = 1, 2, \ldots, K$ and time point $t = 1, 2, \ldots, T$. Given these observations, we construct a multilevel model for each of the parameters in the HMM with $q$ observable categorical outcomes, and $m$ hidden states. That is, each parameter is assumed to follow a given distribution, and the parameter value of a given subject represents a draw from this common (i.e., population level) distribution. Hence, in the multilevel Bayesian HMM, the parameters are: the subject-specific transition probability matrix $\boldsymbol{\Gamma}_k$ with transition probabilities $\gamma_{k,ij}$ (and zero-diagonal, i.e., no self-transitions), the subject-specific state-dependent probability distribution denoting subject-specific the probabilities $\boldsymbol{\theta}_{k,i}$ of categorical outcomes within behavioral state $i$, and the subject-specific median state durations exp($\mu_{k,i}$).  We assume the variance of the state durations $\sigma_i^2$ to be equal over subjects, see below. The initial probabilities of the states $\pi_{k,j}$ are not estimated as $\pi_{k}$ is assumed to be the stationary distribution of $\boldsymbol{\Gamma}_k$. Subsequently, the parameter values of the subjects are assumed to be realizations of a model component and state specific (multivariate) Normal distribution. We discuss the multilevel model for the three components of the HMM ($\boldsymbol{\Gamma}_k$, $\boldsymbol{\theta}_{k,i}$, and exp($\mu_{k,i}$)) separately. Table \ref{SymbolDescription} provides an overview of the used symbols in the multilevel models related to the three components of the HMM. We use the subscript 0 to denote values of the hyper-prior distribution parameters.

\begin{table}
\caption{Elements of the multilevel HMM}
\begin{tabular}{l p{10cm}}
\hline
\hline
\textbf{Symbol}	& \textbf{Description}\\
\hline
$k$			& subject $k \in \{1, 2, \ldots, K \}$, where $K$ is the total number of subjects in the  subject dataset \\
$t$			& Time point $t \in \{1, 2, \ldots, T \}$, where $T$ is the total length of each sequence of observations, and $T$ is assumed equal over subjects\\
$q$			& Number of distinct observation categories\\
$m$			& Number of distinct states\\
$S_{k,t}$ 		& State for subject $k$ at time point $t$ for $S \in \{1, 2, \ldots, m \}$\\
$i$ 			& Realization of the current state $S_t$ or $S_n$, where $i \in \{1, 2, \ldots , m\}$\\
&\\
$\boldsymbol{\Gamma_k} = [\gamma_{k,ij}]$	& Subject-specific transition probability matrix between states with the probabilities $\gamma_{k,ij}$ of transitioning from state $S_{k,n} = i$ to state $S_{k,n+1} = j$, where $i \neq j$ \\
$\boldsymbol{\omega}_{k,i}$ 	& subject $k$ state $i$ specific batch of $m-2$ random intercepts that model the transitions from state $i$ to the next state $j$, where $i \neq j$\\
$\boldsymbol{\bar{\omega}}_{i}$, $\Psi_i$ & State $i$ specific population mean vector over, and covariance between, the subject $k$  batches of the $m-2$ random intercepts $\boldsymbol{\omega}_{k,i}$, respectively \\
$\boldsymbol{\omega}_{0}$, $K_0$		& Values of the parameters of the hyper-prior on the population mean vector $\boldsymbol{\bar{\omega}}_{i}$ \\
$\Psi_0$, $df_0$ 					& Values of the parameters of the hyper-prior on the population covariance $ \Psi_i$ \\
 	&\\
$O_{k,t}$ 		& Observed event for subject $k$ at time point $t$ for $O \in \{1, 2, \ldots q\}$\\
$l$			& Realization of current event $O_{k,t}$, where $l \in \{1, 2, \ldots, q \}$\\ 
$\boldsymbol{\theta}_{k,i} = [\theta_{k,il}]$	&  Subject-specific state $i$ categorical conditional distribution, with the probabilities $\text{p}_{k,il}$ of observing the behavioral act $O_{k,t} = l $ in state $S_{k,t} = i$\\
$\boldsymbol{\nu}_{k,i} $ 		& Subject $k$ state $i$ specific batch of $q-1$ random intercepts that model the probability of a behavioral act within state $i$\\
$\boldsymbol{\bar{\nu}}_{i}$, $ \Phi_{i}$ & State $i$ specific population mean vector over, and covariance between, the subject $k$  batches of the $q-1$ random intercepts  $\boldsymbol{\nu}_{k,i}$, respectively \\
$\boldsymbol{\nu}_{0}$, $K_0$ 		& Values of the parameters of the hyper-prior on the population mean vector $\boldsymbol{\bar{\nu}}_{i}$\\
$\Phi_0$, $df_0$ 				&Values of the parameters of the hyper-prior on the population covariance $ \Phi_{i}$\\
\hline
\label{SymbolDescription}
\end{tabular}%
\end{table}

\subsubsection{Multilevel model for the state-dependent probabilities $\boldsymbol{\theta}_{k,i}$} In the standard (non-multilevel) Bayesian HMM estimation, we specified a Dirichlet prior distribution on the  state-dependent probabilities $\boldsymbol{\theta}_{i}$. To provide a flexible model that allows for the inclusion of random effects, and for future inclusion of covariates, we follow @altman2007 and extend  the subject-specific state-dependent probabilities $\boldsymbol{\theta}_{k,i}$ to a multinomial logit (MNL) model. Hence, we utilize a linear predictor function to estimate the probability of observing behavioral act $l$ within behavioral state $i$. As we do not incorporate any covariates in the model as yet, the state $i$ specific linear predictor function consists of $q-1$ intercepts. That is, each behavioral act $l$ has its own intercept, with the exception of the first behavioral act in the set for which the intercept is omitted for reasons of model identification (i.e., not all probabilities can be estimated freely as within subject $k$ and state $i$ the probabilities need to add up to 1). By making the intercepts random (i.e., each subject has its own intercept), we accommodate heterogeneity between subjects in their state conditional probabilities. Hence, in the MNL model for $\boldsymbol{\theta}_{k,i}$, subject $k$'s probabilities of observing behavioral act $l \in \{1, 2, \ldots, q \}$ within a state $i \in \{1, 2, \ldots , m\}$, ${\theta}_{k,il}$, are modeled using $m$ batches of $q-1$ random intercepts, $\boldsymbol{\nu}_{k,i} = (\nu_{k,12}, \nu_{k,13}, \ldots, \nu_{k,1q}, \nu_{k,22}, \nu_{k,23},\ldots, \nu_{k,2q}, \ldots, \nu_{k,m2}, \nu_{k,m3},$  $\dots, \nu_{k,mq})$. That is, 
\begin{equation}
{\theta}_{k,il} = \frac{\text{exp}(\nu_{k,il})}{1 + \sum_{\bar{l} = 2}^q \text{exp}(\nu_{k, i\bar{l}})},
\end{equation}
where $K$, $m$, and $q$ are the number of subjects, states, and categorical outcomes, respectively.  The numerator is set equal to one for $l = 1$, making the first behavioral act  in the set the baseline category in every state.

\subsubsection{Multilevel model for the transition probability matrix $\boldsymbol{\Gamma_k}$ with transition probabilities $\boldsymbol{\gamma_{k,ij}}$} Similar to the state-dependent probabilities $\boldsymbol{\theta}_{k,i}$, we extend each set of state $i$ specific state transition probabilities $\gamma_{k,ij}$ to a MNL model, to use a linear predictor function to estimate the probability to transition from behavioral state $i$ to state $j$ ($i \neq j$). The linear predictor function consists of $m-2$ random intercepts to allow for heterogeneity between subjects in their probabilities to switch between states. That is, within row $i$ of the transition probability matrix $\boldsymbol{\Gamma_k}$, each state $j$ has its own intercept, where the intercept that relates to self-transitioning  $\gamma_{ii}$ is omitted, as well as the intercept for transitioning to the first "true state" in the set (i.e., not counting the omitted self-transitions) for reasons of model identification (i.e., not all probabilities can be estimated freely as the row-probabilities need to add up to 1). Hence, each subject's probability to transition from behavioral state $i \in\{1, 2, \ldots, m \}$ to state $j \in \{1, 2, \ldots, m, i \neq j \}$ is modeled using $m$ batches of $m-2$ random intercepts, $\boldsymbol{\omega}_{k,i} = (\omega_{k,13}, \ldots, \omega_{k,1m}, \omega_{k,23}, \ldots, \omega_{k,2m},$ $\ldots, \omega_{k,m2},$ $\dots,$ $\omega_{k,m(m-1)})$. That is, 
\begin{equation}
\gamma_{k,ij} = \frac{\text{exp}(\omega_{k,ij})}{1 + \sum_{\bar{j} \in Z} \text{exp}(\omega_{k, i\bar{j}})} ,  i \neq j  \quad \text{with} \ 
\gamma_{ii} = 0,
\end{equation}
\begin{equation}
\text{where} \ Z \in \{1, 2, \ldots, m, \ Z \neq i \ \text{and} \ Z \neq 2 \ \text{if} \ i = 1, \ \text{otherwise} \  Z \neq 1\  \} \nonumber
\end{equation}
where $K$ and $m$ are again the number of subjects in the  behavioral data set, and the distinct number of states, respectively. The numerator is set equal to 1 for $j = 2$ if $i = 1$, and for $j = 1$ otherwise, making the first behavioral state (not counting self-transitions) of every row  of the transition probability matrix $\boldsymbol{\Gamma}_k$ the baseline category. \
Each batch of random intercepts $\boldsymbol{\omega}_{k,i}$ comes from a common population level multivariate Normal distribution with mean vector $\boldsymbol{\bar{\omega}}_{i}$ and covariance $\Psi_i$ that denotes the covariance between the $m - 2$ intercepts over subjects and models the dependency between the probabilities of states within random intercept batch $\boldsymbol{\omega}_{k,i}$ (i.e., we specify a state specific multivariate Normal prior distribution on the subject-specific $\boldsymbol{\omega}_{k,i}$ parameters). A convenient hyper-prior on the hyper-parameters of the population level prior distribution is a multivariate Normal distribution for the mean vector $\boldsymbol{\bar{\omega}}_{i}$ and an Inverse Wishart distribution for the covariance $\Psi_i$. That is, 
\begin{align}
S_{k, n = 2, \ldots, N} \: \sim \boldsymbol{\Gamma}_{k, S_{k, n-1}} \quad &\text{with} \quad \boldsymbol{\Gamma}_{k, i}  \: \sim \text{MNL}\big(\boldsymbol{\omega}_{k,i}\big), \label{tpmPriorHier}\\
\boldsymbol{\omega}_{k,i} \: \sim \text{N}\big(\boldsymbol{\bar{\omega}}_{i}, \Psi_i\big) \quad &\text{with} \quad   \boldsymbol{\bar{\omega}}_{i} \: \sim \text{N}\big(\boldsymbol{\omega}_{0}, \tfrac{1}{K_0}\Psi_i \big),  \label{popTmpHier} \\
&\text{and} \quad   \Psi_i \: \sim \text{IW}\big(\Psi_0, df_0 \big), \nonumber
\end{align}
where the subject-specific probability distribution of the current state $S_{k,n}$ is given by the row of the transition probability matrix $\mathbf{\Gamma}_k$ corresponding to the previous state in the hidden state sequence $S_{k, n-1}$. The probability distribution of $S_{k,n}$ given by $\mathbf{\Gamma}_k$ holds for states after the first segment, i.e., $n$ starts at 2 as there is no previous state in the hidden state sequence for state $S_{k,n}$ at $n$ = 1. The probability of the first state in the hidden state sequence $S_{k,1}$ is given by the initial probabilities of the states $\pi_{k,j}$. The parameters $\boldsymbol{\omega}_{0}$ and $K_0$ denote the values of the parameters of the hyper-prior on the population mean vector $\boldsymbol{\bar{\omega}}_{i}$, where $\boldsymbol{\omega}_{0}$ represent a vector of means and $K_0$ denotes the number of observations (i.e., the number of hypothetical prior subjects) on which the prior mean vector $\boldsymbol{\omega}_{0}$ is based. The parameters $\Psi_0$ and $df_0$, respectively, denote values of the covariance and the degrees of freedom of the hyper-prior Inverse Wishart distribution on the population variance $\Psi_i$ of the subject-specific random intercepts $\boldsymbol{\omega}_{k,i}$.  Again, note that we chose the values of the parameters of the hyper-prior distributions that result in uninformative  hyper-prior distributions, as such the values of the parameters of the hyper-priors are assumed invariant over the states $i$.  

\section{Hybrid Metropolis within Gibbs sampler used to fit the multilevel HMM}
Given the above distributions, our goal is to construct the joint posterior distribution of the parameters - i.e., the subject-specific hidden state sequences, the individual level (i.e., subject-specific) parameters and the population level parameter estimates - given the observations (i.e., the observed event sequences for all $k$ subjects that are analyzed simultaneously as one group and the hyper-prior parameter values)
\begin{align}
& \Pr\big(S_{k,t}, \mathbf{\Gamma}_{k,i}, \boldsymbol{\omega}_{k,i}, \boldsymbol{\bar{\omega}}_{i}, \Psi_i, \boldsymbol{\theta}_{k,i}, \boldsymbol{\nu}_{k,i}, \boldsymbol{\bar{\nu}}_{i}, \Phi_{i} \mid O_{k,t}\big) \nonumber \\
& \quad \propto \Pr\big(O_{k,t} \mid S_{k,t},  \boldsymbol{\theta}_{k,i} \big)  \Pr\big(S_{k,t} \mid \mathbf{\Gamma}_{k,i}  \big) \Pr\big( \boldsymbol{\theta}_{i} \mid \boldsymbol{\nu}_{k,i} \big)  \Pr\big(\mathbf{\Gamma}_i  \mid \boldsymbol{\omega}_{k,i} \big)  \Pr\big( \boldsymbol{\nu}_{k,i} \mid \boldsymbol{\bar{\nu}}_{i}, \Phi_{i}\big) \Pr\big(\boldsymbol{\omega}_{k,i} \mid  \boldsymbol{\bar{\omega}}_{i}, \Psi_i \big) \nonumber \\
&  \quad  \quad   \quad \quad  \Pr\big(\boldsymbol{\bar{\nu}}_{i} \mid  \boldsymbol{\nu}_{0}, K_0, \Phi_i \big)  \Pr\big(\Phi_{i} \mid \Phi_0, df_0 \big) \Pr\big(\boldsymbol{\bar{\omega}}_{i} \mid  \boldsymbol{\omega}_{0}, K_0, \Psi_{i} \big) \Pr\big(\Psi_i \mid \Psi_0, df_0 \big)   \nonumber \\ 
\end{align}
by drawing samples from the posterior distribution. We follow a MCMC sampler algorithm to iteratively sample from the appropriate conditional posterior distributions of $\boldsymbol{\nu}_{k,i}$, $\boldsymbol{\omega}_{k,i}$, $\mu_{k,i}$, $\sigma_{i}^2$,  $\boldsymbol{\bar{\nu}}_{i}$, $\Phi_{i}$, $\boldsymbol{\bar{\omega}}_{i}$, $\Psi_i$,   $\bar{\mu}_{i}$, and $\tau_i^2$ given the remaining parameters in the model (see below). The conditional posterior distributions of all parameters are provided in the Section "\textit{Full conditional posterior distributions of the multilevel HMM}". \
In Bayesian estimation, it is preferable to use the natural conjugate prior as prior distribution, as this conveniently results in a closed form expression of the (conditional) posterior distribution(s), making Gibbs sampling possible. However, because the non-conjugate Normal prior provides a much more intuitive interpretation of the prior population level distribution compared to using the natural conjugate prior of the MNL model, and because the asymptotic Normal approximation is excellent for the MNL likelihood [@rossi2012], we opt for the former and do not use the conjugate prior of the MNL model. Therefore, we cannot use a Gibbs sampler to update the parameters of the subject-specific state-dependent distributions and the subject-specific transition probabilities,  $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$, respectively. Instead, we use a combination of the Gibbs sampler and Metropolis algorithm, i.e., a Hybrid Metropolis within Gibbs sampler. That is, we use a Metropolis sampler to update $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$, and we use a Gibbs sampler to update all other model parameters. There are various types of Metropolis algorithms, and each type  involves specific choices. Simulation studies showed that, in line with @rossi2012, the Random Walk (RW) Metropolis sampler outperformed the Independence Metropolis sampler in terms of efficiency for estimating the parameters of the (multilevel) HMM, we chose to use the RW Metropolis sampler to update the parameters of the subject-specific state-dependent distributions ($\boldsymbol{\nu}_{k,i}$) and subject-specific state transition probabilities ($\boldsymbol{\omega}_{k,i}$) in our Hybrid Metropolis within Gibbs sampler.\
The Hybrid Metropolis within Gibbs sampler for the multilevel HMM proceeds in a similar fashion as the Gibbs sampler for the HMM: first the hidden state sequences are sampled (for each subject separately), after which the (individual level and population level) parameters are sampled given the observed event sequence (for each subject, $O_{k,t}$), the sampled hidden state sequences (of each subject, $S_{k,n}$), and the current values of the remaining parameters in the model.  

\subsubsection{Stepwise walkthrough of the used hybrid Metropolis within Gibbs sampler}
The Hybrid Metropolis within Gibbs sampler used to fit the multilevel HMM proceeds as described below. We use the subscript $c$ to denote the current (i.e., updated using a combination of the value of the hyper-prior and the data) parameters of the conditional posterior distributions. 

\begin{itemize}

\item  Given the observed event sequence for each subject $k$ $O_{k,1}, O_{k,2}, \ldots, O_{k,T}$ and the current values of the parameters $\mathbf{\Gamma}$ and $\boldsymbol{\theta}_i$, a hidden state sequence $S_{k,1}, S_{k,2}, \ldots, S_{k,T}$ is sampled for each subject seperately, utilizing the forward probabilities. Note that for each subject $k \in \{1, 2, \ldots, K\}$, the subject-specific parameters (i.e., $\mathbf{\Gamma}_{k,i}$ and $\boldsymbol{\theta}_{k,i}$) are used as input for the forward-backward recursions.  

\item Given the subject-specific sets of intercepts  $\boldsymbol{\nu}_{k,i}$  and  $\boldsymbol{\omega}_{k,i}$ related to the subject-specific state-dependent probabilities  $\boldsymbol{\theta}_{k,i}$ and the subject-specific state transition probability matrix $\boldsymbol{\Gamma}_k$, respectively, new parameter estimates are drawn for the population mean and covariance of the subject-specific sets of intercepts $\boldsymbol{\nu}_{k,i}$  and  $\boldsymbol{\omega}_{k,i}$ from their conditional posterior distributions $\Pr(\boldsymbol{\bar{\nu}}_{i} \mid\ )$, $\Pr(\Phi_{i} \mid \ )$, $\Pr(\boldsymbol{\bar{\omega}}_{i} \mid \ )$, and $\Pr(\Psi_i \mid \ )$, respectively. \
That is, first the state $i$ specific population variance-covariance matrices $\Phi_{i}$ and $\Psi_i$ (i.e., the covariance between intercepts for the state i and subject k specific intercept vector $\boldsymbol{\nu}_{k,i}$ or $\boldsymbol{\omega}_{k,i}$) are drawn from $\Pr(\Phi_{i} \mid \ ) \sim \text{IW}(\Phi_{ci}, df_c)$ and $\Pr(\Psi_i \mid \ ) \sim \text{IW}(\Psi_{ci}, df_c )$, where  $\Phi_{ci}$ and $\Psi_{ci}$ represent a combination of the chosen prior values $\Phi_0$ and $\Psi_0$ and the state $i$ specific covariance observed over subjects in $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$, respectively, and $df_{c}$ represent a combination of the chosen prior value $df_{0}$ and the number of subjects in the analyzed  subject dataset. See @gelman2014 for details on updating the parameters of an Inverse Wishart distribution.\
Next, the state $i$ specific mean population estimates $\boldsymbol{\bar{\nu}}_{i}$ and $\boldsymbol{\bar{\omega}}_{i}$ are drawn from $\Pr(\boldsymbol{\bar{\nu}}_{i} \mid\ ) \sim \text{N}(\boldsymbol{\nu}_{ci}, \tfrac{1}{K_c} \Phi_{i})$ and $\Pr(\boldsymbol{\bar{\omega}}_{i} \mid \ )  \sim \text{N}(\boldsymbol{\omega}_{ci}, \tfrac{1}{K_c} \Psi_i)$, where  $\boldsymbol{\nu}_{ci}$ and $\boldsymbol{\omega}_{ci}$ represent a combination of the chosen prior values $\boldsymbol{\nu}_{0}$ and $\boldsymbol{\omega}_{0}$ and the observed state $i$ specific mean vector over subjects of the sets of intercepts $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$, and $K_{c}$ represents a combination of the prior value $K_{0}$ and the number of subjects in the analyzed dataset. 

\item Given the observed event sequence for each subject $(O_{k,t})$, the sampled hidden state sequences of each subject $(S_{k,t})$, the population distributions for the subject-specific sets of intercepts  $\boldsymbol{\nu}_{k,i}$  and  $\boldsymbol{\omega}_{k,i}$ parameterized by  $\boldsymbol{\bar{\nu}}_{i}$ and $\Phi_{i}$, and $\boldsymbol{\bar{\omega}}_{i}$ and $\Psi_i$, respectively, new estimates of the subject-specific sets of intercepts  $\boldsymbol{\nu}_{k,i}$  and  $\boldsymbol{\omega}_{k,i}$ are drawn from their posterior conditional distribution $\Pr(\boldsymbol{\nu}_{k,i} \mid \ )$ and $\Pr(\boldsymbol{\omega}_{k,i} \mid \ )$ using a Randon Walk (RW) Metropolis sampler.\
That is, to draw new estimates for $\boldsymbol{\nu}_{k,i}$, first a candidate vector $\boldsymbol{\nu}_{k,i [candidate]}$ is sampled from a proposal distribution, which we chose to be an asymptotic normal approximation to the conditional posterior distribution (see below). In the RW Metropolis sampler, the vector of means of the proposal distribution is  equal to the current estimate of $\boldsymbol{\nu}_{k,i}$, and the scale of the distribution (i.e., here the covariance) has to be specified by the user. To define the scale of the proposal distribution, we followed the method outlined by @rossi2012, which is described below. In summary, we use a subject-specific scale parameter $\Sigma_{\nu k,i}$, which is a combination between the prior covariance (i.e., the population covariance $\Phi_{i}$), a covariance matrix that captures the distribution of the data of the individual subject (i.e., for $\boldsymbol{\nu}_{k,i}$, this is the covariance in the observed outcomes within state $i$ for subject $k$), and a scalar $s^2$. Next, the candidate $\boldsymbol{\nu}_{k,i [candidate]}$ drawn from the proposal distribution $\text{N}(\boldsymbol{\nu}_{k,i} , \Sigma_{\nu k,i})$ is accepted with the probability $min(1, \rho_\nu)$, where $\rho_\nu$ is the ratio between the posterior conditional distribution evaluated at the candidate value and the posterior  conditional distribution evaluated at the current value:
\begin{equation}
\rho_\nu = \frac
{L\big(\boldsymbol{\nu}_{k,i [candidate]} \mid O_{k,t}, S_{k,t} = i\big) \Pr\big(\boldsymbol{\nu}_{k,i  [candidate]} \mid \boldsymbol{\bar{\nu}}_{i}, \Phi_{i}\big)}
{L\big(\boldsymbol{\nu}_{k,i [current]} \mid O_{k,t}, S_{k,t} = i\big) \Pr\big(\boldsymbol{\nu}_{k,i  [current]}  \mid \boldsymbol{\bar{\nu}}_{i}, \Phi_{i}\big)}. 
\end{equation} 
If the candidate $\boldsymbol{\nu}_{k,i [candidate]}$ is accepted, the candidate represents the new estimate for $\boldsymbol{\nu}_{k,i}$. If the candidate is not accepted, the estimate for $\boldsymbol{\nu}_{k,i}$ remains unchanged. \\
The new estimates for  $\boldsymbol{\omega}_{k,i}$ are drawn in a similar fashion: a candidate vector   $\boldsymbol{\omega}_{k,i [candidate]}$ is drawn from the proposal distribution $\text{N}(\boldsymbol{\omega}_{k,i} , \Sigma_{\omega k,i})$, and accepted with the probability min(1, $\rho_\omega$): 
\begin{equation}
\rho_\omega = \frac
{L\big(\boldsymbol{\omega}_{k,i [candidate]} \mid S_{k,n}, S_{k,n-1} = i \big) \Pr\big(\boldsymbol{\omega}_{k,i  [candidate]} \mid \boldsymbol{\bar{\omega}}_{i}, \Psi_i\big)}
{L\big(\boldsymbol{\omega}_{k,i [current]} \mid S_{k,n}, S_{k,n-1} = i\big) \Pr\big(\boldsymbol{\omega}_{k,i  [current]}  \mid \boldsymbol{\bar{\omega}}_{i}, \Psi_i\big)}. 
\end{equation} 
Note that the RW Metropolis sampler is repeated for each subject $k \in \{1, 2, \ldots, K\}$. 
\end{itemize}

These steps are repeated for a large number of iterations, and, after discarding the first iterations as a "burn-in" period, the sampled parameter estimates provide the empirical posterior distribution of the model parameters.\
Regarding the acceptance rate of the RW Metropolis sampler for the subject-specific sets of intercepts  $\boldsymbol{\nu}_{k,i}$  and  $\boldsymbol{\omega}_{k,i}$ (i.e., related to the subject-specific state-dependent probabilities  $\boldsymbol{\theta}_{k,i}$ and the subject-specific state transition probability matrix $\boldsymbol{\Gamma}_k$, respectively),  an acceptance rate of $\sim23\%$ is considered optimal when many parameters are being updated at once [@gelman2014]. The number of accepted draws for each of the parameters is stored in XXXXXXX. 

\subsubsection{Scaling the proposal distribution of the RW Metropolis sampler} To obtain the scale parameter $\Sigma_{\nu k,i}$ and $\Sigma_{\omega k,i}$ of the proposal distributions of the RW Metropolis sampler for $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$, respectively, we followed the method outlined by @rossi2012, which has several advantages as discussed below. \
The general challenge of the RW Metropolis sampler is that it has to be "tuned" by choosing the scale of the symmetric proposal distribution (e.g., the variance or covariance of a Normal or multivariate Normal proposal distribution, respectively). The scale of the proposal distribution is composed of a covariance matrix $\Sigma$, which is then tuned by multiplying it by a scaling factor $s^2$. Hence we denote the scale of the proposal distribution by $s^2\Sigma$. The scale $s^2\Sigma$ has to be set such that the drawn parameter estimates cover the entire area of the posterior distribution (i.e.,  the scale $\Sigma$ should not be set too narrow because then only candidate parameters in close proximity of the current parameter will be drawn), but remains reasonably efficient (i.e.,  the scale $\Sigma$ should not be set too wide because then many candidate parameters will be rejected resulting in a slowly progressing chain of drawn parameter estimates).\
There are various options for the covariance matrix $\Sigma$. Often, the covariance matrix $\Sigma$ is set such that it resembles the covariance matrix of the actual posterior distribution. To capture the curvature of each individual subject's conditional posterior distribution, the scale of the RW Metropolis proposal distribution should be customized to each subject. This also facilitates the possibility to let the amount of information available within the data of a subject for a parameter determine to which degree the population level distribution dominates the estimation of the subject-specific parameters (i.e., the individual level parameters). Hence, to approximate the conditional posterior distribution of each subject, the covariance matrix is set to be a combination of the covariance matrix obtained from the subject individual data and the population level covariance matrix $\Phi_{i}$ or $\Psi_i$. To estimate the covariance matrix from the subject individual data, which is only used for the proposal distribution of the RW Metropolis sampler, we simply use a Maximum Likelihood Estimate (MLE), as this quantity is only used for the purpose of scaling the proposal distribution and is not part of the estimated parameter values that constitute the posterior distribution. The MLE estimate of the covariance matrix is obtained by maximizing the likelihood of the Multinomial Logit (MNL) model on the data, and retrieving the Hessian matrix $H_{k,i}$ (i.e., the second order partial derivatives of the likelihood function with respect to the parameters). The covariance matrix of the parameters is the inverse of the Hessian matrix, $H_{k,i}^{-1}$. Hence, the covariance matrices for $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$, are defined by $\Sigma_{\boldsymbol{\nu}_{k,i}} = (H_{\nu k,i} + \Phi_{i}^{-1})^{-1}$ and $\Sigma_{\boldsymbol{\omega}_{k,i}} = (H_{\omega k,i} + \Psi_i^{-1})^{-1}$, respectively. For $\boldsymbol{\nu}_{k,i}$, the data on which the Hessian is obtained is the frequency with which a behavioral act is observed in state $i$ of subject $k$. For $\boldsymbol{\omega}_{k,i}$, this data is the frequency with which state $i$ transitions to another state within subject $k$. Hence, the subject-specific covariance matrix (i.e., the inverse of the Hessian matrix) is based on the sampled hidden state sequence. Therefore, the MLE estimates of the subject-specific covariance matrices that are used for the RW Metropolis proposal distributions have to be obtained in each iteration, as the sampled hidden state sequence changes in each iteration. \
A potential problem with maximizing the log-likelihood of each subject's individual data, is that a certain state might not be sampled for a subject (e.g., if a subject does not show the behavioral act \emph{medium in shelter} or \emph{long in shelter} in the observed event sequence). To circumvent this problem, we modify the individual likelihood function by adding a so-called regularizing likelihood function that has a defined maximum to the individual-level likelihood function. We maximize the resulting pooled likelihood function in order to obtain the MLE estimates. Here, we use the likelihood function of the combined data over all subjects that are considered to be part of one group as the regularizing likelihood function. The pooled likelihood function is scaled by $1-w \times \text{individual-level likelihood} + w \times \text{overall likelihood}^{n.obs_k / N.obs}$, so that the overall likelihood function does not dominate the individual-level likelihood function, and where $n.obs_k$ is the number of data observations for subject $k$ and $N.obs$ is the total number of data observations over all subjects in a group.\
Now that we defined the covariance matrix $\Sigma$ for the scale of the RW Metropolis sampler proposal distribution, we have to define the scalar factor $s^2$ to obtain the scale $s^2\Sigma$ of the proposal distribution. As in @rossi2012}, we adopt the scaling proposal of @roberts2001, and set scaling to $s^2 = (2.93 / \sqrt{\text{n.param}})^2$, where $n.param$ is the number of parameters to be estimated for $\boldsymbol{\omega}_{k,i}$ or $\boldsymbol{\nu}_{k,i}$ in the RW Metropolis sampler, which equals $m - 2$ in case of $\boldsymbol{\omega}_{k,i}$ (where $m$ denotes the number of states) and $q - 1$ in case of $\boldsymbol{\nu}_{k,i}$ (where $q$ denotes the number of categorical outcomes). \
In summary, the scale parameter $s^2\Sigma_{\nu k,i}$ and $s^2\Sigma_{\omega k,i}$ of the proposal distributions of the RW Metropolis sampler for $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$ are defined as: 
\begin{align}
s^2\Sigma_{\nu k,i} = (2.93 / \sqrt{q-1})^2 & \: \times \: (H_{\nu k,i} + \Phi_{i}^{-1})^{-1}, \ \text{and} \\
s^2\Sigma_{\omega k,i} = (2.93 / \sqrt{m-2})^2 & \: \times \: (H_{\omega k,i} + \Psi_i^{-1})^{-1} ,
\end{align}
where $H_{\nu k,i}$ is the Hessian of the $k^{th}$ subject's data of the frequency with which a behavioral act is observed within state $i$ evaluated at the MLE of the pooled likelihood, $H_{\omega k,i}$ is the Hessian of the $k^{th}$ subject's data of the frequency with which state $i$ transitions to another state evaluated at the MLE of the pooled likelihood, and $\Phi_{i}^{-1}$ and $\Psi_i^{-1}$ are the inverses of the population level covariance matrices. This provides us with $m$ pairs of scale parameters that closely resemble the scale of the subject-level conditional posterior distribution, and that 1) are automatically tuned (i.e., we do not require experimentation to determine $s^2$ to tune the covariance matrix), 2) allow the amount of information available within the data of a specific subject to determine  the degree to which the population level distribution dominates  the estimation of that subject's level parameters, and 3) do not require each state to be sampled in the hidden state sequence as not each individual-level likelihood is required to have a maximum.

\subsubsection{Full conditional posterior distributions of the multilevel HMM}
In the hybrid Metropolis within Gibbs sampler, all level 2 model parameters are directly sampled from their full conditional posterior distributions. The full conditional posterior distributions are obtained by applying Bayes theorem, combining the (hyper-)prior distribution of the model parameter and the likelihood function. Direct sampling from the conditional posterior distributions for these model parameters is possible, as the choice of the (hyper-)prior distribution results in a closed form expression of the full conditional posterior distribution. That is: 
\begin{itemize}
  \item The full conditional posterior distributions of $\Phi_{i} $ and $\Psi_i$ (i.e., the state $i$ specific population covariance between the subject $k$ batches of the $q-1$ random intercepts  $\boldsymbol{\nu}_{k,i}$ pertaining to the subject-specific state-dependent probabilities $\boldsymbol{\theta}_{k,i}$, and the state $i$ specific population covariance between the subject $k$ batches of the $m-2$ random intercepts $\boldsymbol{\omega}_{k,i}$ pertaining to the subject-specific state transition probabilities, $\boldsymbol{\Gamma}_k$) are: 
    \begin{align}
  \Pr(\Phi_{i} \mid \ ) \: & \sim \text{IW}(\Phi_{ci}, df_c)\\
  \Phi_{ci} \: & = \tfrac{1}{\Phi_{0}} + SS_\nu + \frac{K_0K}{K_0 + K}(\boldsymbol{\nu}_0 - \bar{\bar{\boldsymbol{\nu}}}_{k,i})(\boldsymbol{\nu}_0 - \bar{\bar{\boldsymbol{\nu}}}_{k,i})^T \nonumber \\ 
  SS_\nu \: & = \sum_k (\boldsymbol{\nu}_{k,i} - \bar{\bar{\boldsymbol{{\nu}}}}_{k,i}) (\boldsymbol{\nu}_{k,i} - \bar{\bar{\boldsymbol{{\nu}}}}_{k,i})^T\nonumber \\ 
  df_c \: & = df_0 + K \nonumber
  \end{align}
  \begin{align}
  \Pr(\Psi_i \mid \ ) \: & \sim \text{IW}(\Psi_{ci}, df_c ) \\
  \Psi_{ci} \: & = \tfrac{1}{\Psi_{0}} + SS_\omega + \frac{K_0K}{K_0 + K}(\boldsymbol{\omega}_0 - \bar{\bar{\boldsymbol{\omega}}}_{k,i})(\boldsymbol{\omega}_0 - \bar{\bar{\boldsymbol{\omega}}}_{k,i})^T \nonumber \\
  SS_\omega \: & = \sum_k (\boldsymbol{\omega}_{k,i} - \bar{\bar{\boldsymbol{{\omega}}}}_{k,i}) (\boldsymbol{\omega}_{k,i} - \bar{\bar{\boldsymbol{{\omega}}}}_{k,i})^T \nonumber \\
  df_c \: & = df_0 + K  \nonumber
  \end{align}
  where $x^T$ is the transpose of $x$, $\boldsymbol{\nu}_0$ and $\boldsymbol{\omega}_0$ denote a vector of chosen mean values of the Normal hyper-prior distribution on the population mean vector $\bar{\boldsymbol{\nu}}_i$ and $\bar{\boldsymbol{\omega}}_i$, respectively, and $K_0$ denotes the number of observations (i.e., the number of hypothetical prior subjects) on which the prior mean vectors $\bar{\boldsymbol{\nu}}_i$ and $\boldsymbol{\omega}_{0}$ are based, $K$ denotes the total number of subjects in the dataset, $\Phi_0$ and $\Psi_0$ denote the chosen covariance values of the Inverse Wishart hyper-prior distribution on the population covariance $\Phi_i$ and $\Psi_i$, respectively, $\bar{\bar{\boldsymbol{\omega}}}_{k,i}$ and $\bar{\bar{\boldsymbol{{\nu}}}}_{k,i}$ denote the mean over the subject-specific parameters $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$ (i.e., the subject-specific intercepts associated to the state-dependent probabilities and the state transition probabilities, respectively), respectively, and $df_0$ denotes the prior specified degrees of freedom of the Inverse Wishart hyper-prior distribution on the population covariance $\Phi_i$ and $\Psi_i$. 
  \item The full conditional posterior distributions of $\boldsymbol{\bar{\nu}}_{i}$ and $\boldsymbol{\bar{\omega}}_{i}$ (i.e., the state $i$ specific population mean vector of the subject-specific batches of intercepts $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$ pertaining to the state-dependent probabilities and state transition probabilities, respectively) are: 
    \begin{align}
  \Pr(\boldsymbol{\bar{\nu}}_{i} \mid\ ) \: & \sim \text{N}(\boldsymbol{\nu}_{ci}, \tfrac{1}{K_c} \Phi_{i})\\
  \boldsymbol{\nu}_{ci} \: & = \frac{K_0 \boldsymbol{\nu}_{0} + K\bar{\bar{\boldsymbol{{\nu}}}}_{k,i}} {K_0 + K} \nonumber \\
  K_c \: & = K + K_0 \nonumber
  \end{align}
  \begin{align}
  \Pr(\boldsymbol{\bar{\omega}}_{i} \mid \ ) \: & \sim \text{N}(\boldsymbol{\omega}_{ci}, \tfrac{1}{K_c} \Psi_i)\\
  \boldsymbol{\omega}_{ci} \: &=  \frac{K_0 \boldsymbol{\omega}_{0} + K\bar{\bar{\boldsymbol{{\omega}}}}_{k,i}} {K_0 + K} \nonumber \\
  K_c \: & = K + K_0 \nonumber
  \end{align}
  where $\boldsymbol{\nu}_0$ and $\boldsymbol{\omega}_0$ denote the chosen mean values of the Normal hyper-prior distribution on the population mean vector $\bar{\boldsymbol{\nu}}_i$ and $\bar{\boldsymbol{\omega}}_i$, respectively, $K_0$ denotes the number of observations (i.e., the number of hypothetical prior subjects) on which the prior mean vectors $\boldsymbol{\nu}_0$ and $\boldsymbol{\omega}_0$ are based, $K$ denotes the total number of subjects in the dataset, and $\bar{\bar{\boldsymbol{\omega}}}_{k,i}$ and $\bar{\bar{\boldsymbol{{\nu}}}}_{k,i}$ denote the means of the subject-specific parameters $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$, respectively. 
    \end{itemize}
  For the intercepts  $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$, related to the subject-specific state-dependent probabilities of observing an act $\boldsymbol{\theta}_{k,i}$ and the subject-specific state transition probability matrix $\boldsymbol{\Gamma}_{k}$, respectively, the choice of prior distributions does not result in closed form expressions of the full conditional posterior distributions. That is, for the subject-specific sets of intercepts  $\boldsymbol{\nu}_{k,i}$ related to the subject-specific state-dependent probabilities of observing an act within state $i$, the full conditional posterior distribution when we assess a standard multivariate normal prior is: 
    \begin{align}
  Pr(\boldsymbol{\nu}_{k,i} \mid ) \: & \propto L\big(\boldsymbol{\nu}_{k,i} \mid O_{k,t}, S_{k,t} = i\big) \Pr\big(\boldsymbol{\nu}_{k,i} \mid \boldsymbol{\bar{\nu}}_{i}, \Phi_{i}\big),\\
  \Pr\big(\boldsymbol{\nu}_{k,i} \mid \boldsymbol{\bar{\nu}}_{i}, \Phi_{i}\big) \: & \sim \text{N}( \boldsymbol{\bar{\nu}}_{i}, \Phi_{i}\big)), \nonumber
  \end{align}
  and the likelihood is the product of the probabilities of the observed outcomes $O_{k,t} = l \in \{1, 2, \ldots, q\}$ within sampled states $S = i$ in subject $k$ over time points $t$: 
    \begin{align}
  L\big(\boldsymbol{\nu}_{k,i} \mid O_{k,t}, S_{k,t} = i\big) \: & = \prod_{{t}} Pr( O_{k,{t}} = l \mid S_{k,t} = i, \boldsymbol{\nu}_{k,i}), \\
  Pr( O_{k,{t}} = l \mid S_{k,t} = i, \boldsymbol{\nu}_{k,i}) \: & = \frac{\text{exp}(\nu_{k,il})}{1 + \sum_{\bar{l} = 2}^q \text{exp}(\nu_{k, i\bar{l}})}, \nonumber
  \end{align}
  where the product is restricted to the set of time points that coincide with the sampled state $S$ for subject $k$ at time point $t$ being $i$, and $q$ is the number of categorical outcomes.  The numerator is set equal to one for $l = 1$, making the first behavioral act  in the set the baseline category in every state. \
  For the subject-specific sets of intercepts $\boldsymbol{\omega}_{k,i}$ related to the state-transition probabilities to transition from state $i$ to any of the other states $j \in \{1, 2, \ldots,$ $m\},$ $i \neq j$, the full conditional posterior distribution when we assess a standard multivariate normal prior is: 
    \begin{align}
  Pr(\boldsymbol{\omega}_{k,i} \mid ) \: & \propto L\big(\boldsymbol{\omega}_{k,i} \mid S_{k,n}, S_{k,n-1} = i \big) \Pr\big(\boldsymbol{\omega}_{k,i} \mid \boldsymbol{\bar{\omega}}_{i}, \Psi_i\big),\\
  \Pr\big(\boldsymbol{\omega}_{k,i} \mid \boldsymbol{\bar{\omega}}_{i}, \Psi_{i}\big) \: & \sim \text{N}(\boldsymbol{\bar{\omega}}_{i}, \Psi_{i}), \nonumber
  \end{align}
  and the likelihood is the product of the probabilities of the observed transitions from state $i$ in the previous segment $n-1$ to any of the other states $S_{k,n} = j$ over segments $n$ in subject $k$:  
    \begin{align}
  L\big(\boldsymbol{\omega}_{k,i} \mid S_{k,n}, S_{k,n-1} = i \big) \: & = \prod_{{n}} Pr( S_{k,{n}} = j \mid S_{k,n-1} = i, \boldsymbol{\omega}_{k,i}), \\
  Pr( S_{k,{n}} = j \mid S_{k,n-1} = i, \boldsymbol{\omega}_{k,i}) \: & =  \frac{\text{exp}(\omega_{k,ij})}{1 + \sum_{\bar{j} \in Z} \text{exp}(\omega_{k, i\bar{j}})}, \nonumber
  \end{align}
  \begin{equation}
  \text{where} \ Z \in \{1, 2, \ldots, m, \ Z \neq 1 \} \nonumber
  \end{equation}
  where the product is restricted to the set of segments that coincide with the sampled state $S$ in the previous segment $n-1$ being $i$ for subject $k$, and $m$ is the number of states.  The numerator is set equal to 1 for $j = 1$, making the first behavioral state of every row  of the transition probability matrix $\boldsymbol{\Gamma}_k$ the baseline category.\\
  As the conditional posterior distributions for $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$ do not result in a closed form expression of a know distribution, we cannot directly sample values of $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$ from their conditional posterior distributions with pre-defined equations on how to obtain the current (i.e., updated using a combination of the value of the hyper-prior and the data) parameters of the conditional posterior distributions. Instead, new values for $\boldsymbol{\nu}_{k,i}$ and $\boldsymbol{\omega}_{k,i}$ are sampled using a RW Metropolis sampler, as described above. 

\section{References}
\small{\bibliography{bibliography.bib}}
